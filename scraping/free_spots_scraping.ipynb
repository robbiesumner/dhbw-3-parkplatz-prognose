{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benötigte Pakete\n",
    "bs4 (BeatifulSoup): Extrahieren von Daten aus HTML-Seiten<br>\n",
    "requests: Hier HTTP-Anfrage an Website<br>\n",
    "pandas: Hier zum Einlesen und Datenkonvertierung\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funktion zum Scrapen der aktuell freien Plätze definieren\n",
    "Funktion bekommt Parameter (Kürzel des Parkhauses) übergeben und überschreibt die Daten in der csv-Datei des entsprechenden Parkhauses. Dabei wird der Inhalt der Datei um den neuen Datenpunkt ergänzt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_free_spots(parking_lot):\n",
    "    BASE_URL = \"https://web1.karlsruhe.de/service/Parken/detail.php?id=\"\n",
    "\n",
    "    # Einlesen der bisherigen CSV des Parkhauses\n",
    "    parking_data = pd.read_csv(f\"./data/{parking_lot}.csv\", index_col=0)\n",
    "    # timestamp als \"datetime\"-Format setzen\n",
    "    parking_data[\"timestamp\"] = pd.to_datetime(parking_data[\"timestamp\"])\n",
    "\n",
    "    try:\n",
    "        # Zugriff auf Website\n",
    "        res = requests.get(f\"{BASE_URL}{parking_lot}\")\n",
    "        if res.status_code == 200:\n",
    "            soup = BeautifulSoup(res.text, \"html.parser\")\n",
    "\n",
    "            # Auslesen der aktuell freien Plätze anhand nächsten Element nach Element mit textContent \"Gesamtzahl der freien Stellplätze\"\n",
    "            free_spots = soup.find(\n",
    "                string=\"Gesamtzahl der freien Stellplätze\"\n",
    "            ).find_next(\"td\")\n",
    "\n",
    "            # Erstes h1 (Parkhaustitel) finden (als Ausgangspunkt, um zu timestamp zu kommen)\n",
    "            title = soup.find(\"h1\")\n",
    "            time_string = title.find_next(\"p\").find_next(\"p\")\n",
    "\n",
    "            # Datetime aus Zeitpunktbeschreibung extrahieren\n",
    "            time_string = time_string.text.split(\"von\")[1].split(\"Uhr\")[0]\n",
    "            time_string = time_string.split(\"-\")\n",
    "            time_string = time_string[0].strip() + \" \" + time_string[1].strip()\n",
    "            timestamp = pd.to_datetime(time_string, format=\"%d.%m.%Y %H:%M\")\n",
    "\n",
    "            # Neuen Datenpunkt in parking_data ergänzen, wenn nicht schon vorhanden\n",
    "            if timestamp not in parking_data[\"timestamp\"].values:\n",
    "                parking_data.loc[len(parking_data)] = [timestamp, free_spots.text]\n",
    "                print(\"Data added: \", timestamp)\n",
    "                print(f\"   {free_spots.text} free spots\")\n",
    "                parking_data.to_csv(f\"./data/{parking_lot}.csv\")\n",
    "            else:\n",
    "                print(\"Data already exists: \", timestamp)\n",
    "\n",
    "        else:\n",
    "            print(\"Error: \", res.status_code)\n",
    "    except Exception as e:\n",
    "        print(\"Error: \", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraper ausführen für alle Parkhäuser\n",
    "(Hier wurde **if \\_\\_name\\_\\_ == '\\_\\_main\\_\\_'** entfernt, da Jupyter Notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition Parkhauskuerzel für ID in URL\n",
    "parking_lots = [\n",
    "    \"K01\",\n",
    "    \"K02\",\n",
    "    \"K03\",\n",
    "    \"K04\",\n",
    "    \"N02\",\n",
    "    \"N03\",\n",
    "    \"N05\",\n",
    "    \"N06\",\n",
    "    \"N07\",\n",
    "    \"S01\",\n",
    "    \"S02\",\n",
    "    \"S03\",\n",
    "    \"S04\",\n",
    "    \"S05\",\n",
    "    \"S06\",\n",
    "    \"S07\",\n",
    "    \"W01\",\n",
    "    \"W02\",\n",
    "    \"W03\",\n",
    "    \"W04\",\n",
    "]\n",
    "\n",
    "for parking_lot in parking_lots:\n",
    "    scrape_free_spots(parking_lot)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
